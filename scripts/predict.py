# predict.py
import pandas as pd
import pickle
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from text_preprocessor import tokenize_and_remove_stopwords, clean_text

# 1. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
with open("models/tokenizer_config.pkl", "rb") as f:
    config = pickle.load(f)
tokenizer = config["tokenizer"]
max_len = config["max_len"]

model = load_model("models/sentiment_model.h5")

# 2. ì˜ˆì¸¡ í•¨ìˆ˜ ì •ì˜
def predict_multi_column_csv(csv_path, output_path="predicted_result.csv"):
    df = pd.read_csv(csv_path)
    print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì™„ë£Œ â†’ ì´ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")

    result_dfs = []
    summary = {}

    for col in df.columns:
        comments = df[col].dropna().tolist()
        print(f"\nğŸ¬ ì‘í’ˆ: {col} | ëŒ“ê¸€ ìˆ˜: {len(comments)}")

        #  ë¬¸ìì—´ ì •ì œ + í˜•íƒœì†Œ ë¶„ì„ & ë¶ˆìš©ì–´ ì œê±°
        cleaned_comments = [clean_text(c) for c in comments]
        tokenized = tokenize_and_remove_stopwords(pd.Series(cleaned_comments))

        #  ì‹œí€€ìŠ¤í™” ë° íŒ¨ë”©
        sequences = tokenizer.texts_to_sequences(tokenized)
        padded = pad_sequences(sequences, maxlen=max_len)

        #  ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = model.predict(padded)
        labels = ["ê¸ì •" if p >= 0.5 else "ë¶€ì •" for p in predictions]

        #  ê²°ê³¼ ì €ì¥
        result_df = pd.DataFrame({
            "ì‘í’ˆëª…": col,
            "ì›ë¬¸": comments,
            "ì˜ˆì¸¡ ê°ì •": labels
        })
        result_dfs.append(result_df)

        #  í†µê³„ ì¶œë ¥
        pos = labels.count("ê¸ì •")
        neg = labels.count("ë¶€ì •")
        total = len(labels)
        summary[col] = f"ê¸ì •: {pos / total:.2%} | ë¶€ì •: {neg / total:.2%}"

        print(f"ğŸ“Š ê¸ì •: {pos} / ë¶€ì •: {neg} â†’ ë¹„ìœ¨: {summary[col]}")

    #  ì „ì²´ ê²°ê³¼ ì €ì¥
    final_df = pd.concat(result_dfs, ignore_index=True)
    final_df.to_csv(output_path, index=False, encoding="utf-8-sig")

    summary_df = pd.DataFrame.from_dict(summary, orient="index", columns=["ê¸/ë¶€ì • ë¹„ìœ¨"])
    summary_df.to_csv("prediction_summary.csv", encoding="utf-8-sig")

    print(f"\n ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ {output_path}, prediction_summary.csv")


# 3. ì˜ˆì‹œ ì‹¤í–‰
predict_multi_column_csv("ì›¹ì†Œì„¤/ë¡œë§¨ìŠ¤_ëŒ“ê¸€.csv")

