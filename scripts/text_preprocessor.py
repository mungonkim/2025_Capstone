# text_preprocessor.py
import re
import numpy as np
import pandas as pd
from konlpy.tag import Okt
from tqdm import tqdm

# í˜•íƒœì†Œ ë¶„ì„ê¸° 
okt = Okt()

# ìµœì†Œ í•„ìˆ˜ ë¶ˆìš©ì–´ë§Œ ìœ ì§€
stopwords = [
    'ì˜','ê°€','ì´','ì€','ë“¤','ëŠ”','ê³¼','ë„','ë¥¼','ìœ¼ë¡œ','ìž','ì—','ì™€','í•œ','í•˜ë‹¤',
    'ê·¸ë¦¬ê³ ','í•˜ì§€ë§Œ','ë•Œë¬¸ì—','ê·¸ê²ƒ','ê±°ê¸°','ì €ê¸°','ì´ëŸ°','ì €ëŸ°','ê·¸ëŸ°'
]

# lean_text: ë¬¸ìžì—´ í•˜ë‚˜ë¥¼ ì •ì œ (predictì—ì„œ ì‚¬ìš©ë¨)
def clean_text(text: str) -> str:
    text = re.sub(r"[^ã„±-ã…Žã…-ã…£ê°€-íž£0-9a-zA-Z!?., ]", "", str(text))
    text = re.sub(r"[ã…‹ã…Žã… ã…œ]+", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

#  preprocess: ë°ì´í„°í”„ë ˆìž„ ì „ì²´ ì •ì œ (train/testìš©)
def preprocess(df: pd.DataFrame) -> pd.DataFrame:
    df = df.drop_duplicates(subset=['document'])
    df = df.copy()
    
    df.loc[:, 'document'] = df['document'].astype(str)
    df.loc[:, 'document'] = df['document'].str.replace(r"[^ã„±-ã…Žã…-ã…£ê°€-íž£0-9a-zA-Z!?., ]", "", regex=True)
    df.loc[:, 'document'] = df['document'].str.replace(r"[ã…‹ã…Žã… ã…œ]+", "", regex=True)
    df.loc[:, 'document'] = df['document'].str.replace(r"\s+", " ", regex=True)
    df.loc[:, 'document'] = df['document'].str.strip()
    
    df.loc[:, 'document'] = df['document'].replace('', np.nan)
    df = df.dropna(subset=['document'])
    
    return df

# tokenize_and_remove_stopwords: í˜•íƒœì†Œ ë¶„ì„ + ë¶ˆìš©ì–´ ì œê±°
def tokenize_and_remove_stopwords(series: pd.Series) -> list:
    result = []
    for sentence in tqdm(series, desc="ðŸ”„ Tokenizing"):
        tokens = okt.morphs(sentence, stem=True)
        cleaned = [word for word in tokens if word not in stopwords]
        result.append(cleaned)
    return result
